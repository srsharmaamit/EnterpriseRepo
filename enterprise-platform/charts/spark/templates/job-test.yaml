{{- if .Values.testJob.enabled }}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "spark.fullname" . }}-pi-test
  labels:
    {{- include "spark.labels" . | nindent 4 }}
    app.kubernetes.io/component: test-job
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  {{- include "spark.sccAnnotations" . | nindent 2 }}
spec:
  ttlSecondsAfterFinished: 600
  template:
    metadata:
      labels:
        {{- include "spark.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: test-job
    spec:
      {{- include "spark.imagePullSecrets" . | nindent 6 }}
      serviceAccountName: {{ include "spark.serviceAccountName" . }}
      {{- include "spark.podSecurityContext" . | nindent 6 }}
      restartPolicy: Never
      containers:
        - name: spark-submit
          {{- include "spark.securityContext" . | nindent 10 }}
          image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command:
            - /opt/spark/bin/spark-submit
          args:
            - --master
            - k8s://https://kubernetes.default.svc:443
            - --deploy-mode
            - cluster
            - --name
            - {{ .Values.testJob.name }}
            - --class
            - {{ .Values.testJob.mainClass }}
            - --conf
            - spark.kubernetes.container.image={{ .Values.image.repository }}:{{ .Values.image.tag }}
            - --conf
            - spark.kubernetes.authenticate.driver.serviceAccountName={{ include "spark.serviceAccountName" . }}
            - --conf
            - spark.kubernetes.driver.pod.name={{ .Values.testJob.name }}-driver
            - --conf
            - spark.kubernetes.executor.deleteOnTermination=true
            - --conf
            - spark.driver.cores={{ .Values.testJob.driver.cores }}
            - --conf
            - spark.driver.memory={{ .Values.testJob.driver.memory }}
            - --conf
            - spark.executor.cores={{ .Values.testJob.executor.cores }}
            - --conf
            - spark.executor.memory={{ .Values.testJob.executor.memory }}
            - --conf
            - spark.executor.instances={{ .Values.testJob.executor.instances }}
            {{- if .Values.storage.checkpoint.enabled }}
            - --conf
            - spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpoint-pvc.options.claimName={{ include "spark.checkpointPvcName" . }}
            - --conf
            - spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpoint-pvc.mount.path={{ .Values.storage.checkpoint.path }}
            - --conf
            - spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpoint-pvc.options.claimName={{ include "spark.checkpointPvcName" . }}
            - --conf
            - spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpoint-pvc.mount.path={{ .Values.storage.checkpoint.path }}
            {{- end }}
            {{- if .Values.storage.scratch.enabled }}
            - --conf
            - spark.kubernetes.executor.volumes.persistentVolumeClaim.scratch-pvc.options.claimName={{ include "spark.scratchPvcName" . }}
            - --conf
            - spark.kubernetes.executor.volumes.persistentVolumeClaim.scratch-pvc.mount.path={{ .Values.storage.scratch.path }}
            - --conf
            - spark.kubernetes.driver.volumes.persistentVolumeClaim.scratch-pvc.options.claimName={{ include "spark.scratchPvcName" . }}
            - --conf
            - spark.kubernetes.driver.volumes.persistentVolumeClaim.scratch-pvc.mount.path={{ .Values.storage.scratch.path }}
            {{- end }}
            - {{ .Values.testJob.mainApplicationFile }}
            {{- range .Values.testJob.arguments }}
            - {{ . | quote }}
            {{- end }}
          env:
            - name: SPARK_CONF_DIR
              value: /opt/spark/conf
            {{- range .Values.extraEnvVars }}
            - name: {{ .name }}
              value: {{ .value | quote }}
            {{- end }}
          volumeMounts:
            - name: spark-config
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            {{- range .Values.extraVolumeMounts }}
            - name: {{ .name }}
              mountPath: {{ .mountPath }}
              {{- if .subPath }}
              subPath: {{ .subPath }}
              {{- end }}
            {{- end }}
          resources:
            requests:
              cpu: 100m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi
      volumes:
        - name: spark-config
          configMap:
            name: {{ include "spark.fullname" . }}-config
        {{- range .Values.extraVolumes }}
        - name: {{ .name }}
          {{- toYaml .volume | nindent 10 }}
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{- end }}