# Global configuration shared across all subcharts
global:
  # Private registry configuration
  imageRegistry: my-registry.company.com
  imagePullSecrets:
    - name: private-registry-secret
  
  # Storage configuration
  storageClass: ""  # Use default storage class or set specific one
  
  # Environment-specific settings
  environment: dev  # dev, qa, prod
  
  # Bring Your Own Storage toggle
  useBYOS: false
  
  # Common labels applied to all resources
  commonLabels:
    app.kubernetes.io/managed-by: helm
    app.kubernetes.io/part-of: enterprise-platform
  
  # Security context for OpenShift compatibility
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
  
  # Pod security context
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
  
  # Service Account configuration
  serviceAccount:
    create: true
    annotations: {}
  
  # OpenShift Security Context Constraints
  openshift:
    enabled: true
    scc: restricted-v2  # or anyuid for less restrictive

# Apache Airflow configuration
airflow:
  enabled: true
  
  # Custom image configuration
  image:
    repository: my-registry/airflow
    tag: custom
    pullPolicy: IfNotPresent
  
  # Executor configuration
  executor: KubernetesExecutor
  
  # Database connection (uses postgresql subchart)
  database:
    host: "{{ include \"enterprise-platform.postgresql.fullname\" . }}"
    port: 5432
    database: airflow
    username: airflow
    # Password will be fetched from secret
  
  # Resource configuration
  resources:
    scheduler:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 2Gi
    webserver:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 2Gi
  
  # Storage configuration
  storage:
    logs:
      enabled: true
      size: 5Gi
      storageClass: ""
    dags:
      enabled: true
      size: 1Gi
      storageClass: ""
  
  # Networking
  service:
    type: ClusterIP
    port: 8080
  
  ingress:
    enabled: true
    className: ""
    annotations:
      route.openshift.io/termination: edge
    host: airflow.company.com
    tls:
      enabled: true
  
  # Configuration overrides
  config:
    core:
      dags_folder: /opt/airflow/dags
      executor: KubernetesExecutor
      load_examples: "False"
    webserver:
      enable_proxy_fix: "True"
    kubernetes:
      namespace: "{{ .Release.Namespace }}"
      worker_container_repository: my-registry/airflow
      worker_container_tag: custom
  
  # Metrics configuration
  metrics:
    enabled: true
    port: 8125

# PostgreSQL configuration  
postgresql:
  enabled: true
  
  # Custom image configuration
  image:
    repository: my-registry/postgres
    tag: custom
    pullPolicy: IfNotPresent
  
  # Database configuration
  database:
    name: airflow
    username: airflow
    # Password will be generated or provided via secret
  
  # Storage configuration
  storage:
    data:
      size: 10Gi
      storageClass: ""
  
  # Resource configuration
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
  
  # Service configuration
  service:
    type: ClusterIP
    port: 5432
  
  # Configuration tuning
  config:
    maxConnections: 200
    sharedBuffers: 256MB
    effectiveCacheSize: 1GB
  
  # Metrics configuration
  metrics:
    enabled: true
    port: 9187

# Apache Spark configuration
spark:
  enabled: true
  
  # Custom image configuration
  image:
    repository: my-registry/spark
    tag: custom
    pullPolicy: IfNotPresent
  
  # Kubernetes-native configuration
  mode: k8s-native
  
  # Storage configuration
  storage:
    checkpoint:
      enabled: true
      size: 2Gi
      storageClass: ""
    scratch:
      enabled: true
      size: 2Gi
      storageClass: ""
  
  # Resource configuration (default for Spark jobs)
  resources:
    driver:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
    executor:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 2Gi
  
  # Spark configuration
  config:
    spark.kubernetes.container.image: my-registry/spark:custom
    spark.kubernetes.authenticate.driver.serviceAccountName: "{{ include \"enterprise-platform.spark.serviceAccountName\" . }}"
    spark.kubernetes.executor.deleteOnTermination: "true"
    spark.serializer: org.apache.spark.serializer.KryoSerializer
    spark.sql.adaptive.enabled: "true"
    spark.sql.adaptive.coalescePartitions.enabled: "true"
  
  # Service Account with RBAC
  serviceAccount:
    create: true
    name: ""
    annotations: {}
  
  # RBAC configuration
  rbac:
    create: true
    rules:
      - apiGroups: [""]
        resources: ["pods", "services", "configmaps", "secrets"]
        verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
      - apiGroups: ["apps"]
        resources: ["deployments"]
        verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  
  # Metrics configuration
  metrics:
    enabled: true
    port: 4040

# Environment-specific overlays
environments:
  dev:
    resources:
      requests:
        cpu: 100m
        memory: 512Mi
    replicas: 1
    storage:
      size: 1Gi
  
  qa:
    resources:
      requests:
        cpu: 250m
        memory: 1Gi
    replicas: 2
    storage:
      size: 5Gi
  
  prod:
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
    replicas: 3
    storage:
      size: 20Gi